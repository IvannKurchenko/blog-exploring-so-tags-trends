{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2a29fb89-0199-461e-a53d-d1de548bac6b",
   "metadata": {},
   "source": [
    "## Notebook to convert data into from XML into CSV\n",
    "\n",
    "### Description\n",
    "The main objective of this notebook is to convert Stackoverflow data dump `*.xml` documents into `*.csv` format.\n",
    "The former one is then used for all transformations and calculations, because it is easier to operate with using Pandas.\n",
    "\n",
    "In particularly it converts each row from XML document into CSV and specific attributes into columns. Some attributes are filtered out because they are not relevant for aggregations to make.\n",
    "\n",
    "\n",
    "For instance, `Posts.xml` have the following structure:\n",
    "```xml\n",
    "<?xml version=\"1.0\" encoding=\"utf-8\"?>\n",
    "<posts>\n",
    "  <row Id=\"4\" PostTypeId=\"1\" AcceptedAnswerId=\"7\" CreationDate=\"2008-07-31T21:42:52.667\" Score=\"804\" ViewCount=\"76276\" Body=\"&lt;p&gt;I want to assign the decimal variable &amp;quot;trans&amp;quot; to the double variable &amp;quot;this.Opacity&amp;quot;.&lt;/p&gt;&#xA;&lt;pre class=&quot;lang-cs prettyprint-override&quot;&gt;&lt;code&gt;decimal trans = trackBar1.Value / 5000;&#xA;this.Opacity = trans;&#xA;&lt;/code&gt;&lt;/pre&gt;&#xA;&lt;p&gt;When I build the app it gives the following error:&lt;/p&gt;&#xA;&lt;blockquote&gt;&#xA;&lt;p&gt;Cannot implicitly convert type decimal to double&lt;/p&gt;&#xA;&lt;/blockquote&gt;&#xA;\" OwnerUserId=\"8\" LastEditorUserId=\"16124033\" LastEditorDisplayName=\"Rich B\" LastEditDate=\"2022-09-08T05:07:26.033\" LastActivityDate=\"2022-09-08T05:07:26.033\" Title=\"How to convert Decimal to Double in C#?\" Tags=\"&lt;c#&gt;&lt;floating-point&gt;&lt;type-conversion&gt;&lt;double&gt;&lt;decimal&gt;\" AnswerCount=\"13\" CommentCount=\"4\" FavoriteCount=\"0\" CommunityOwnedDate=\"2012-10-31T16:42:47.213\" ContentLicense=\"CC BY-SA 4.0\" />\n",
    "  <!--other rows-->\n",
    "</posts>\n",
    "```\n",
    "That will be converted into:\n",
    "```csv\n",
    "Tags,ParentId,CreationDate,Id,DeletionDate,PostTypeId,ClosedDate\n",
    "<c#><floating-point><type-conversion><double><decimal>,,2008-07-31T21:42:52.667,4,,1,\n",
    "```\n",
    "\n",
    "### Input \n",
    "This notebook takes as an input two files from raw Stackoverflow data dump:\n",
    "- `Posts.xml` - data with raw posts data;\n",
    "- `Votes.xml` - data with raw votes data;\n",
    "\n",
    "### Output\n",
    "- `posts.xml` - converted posts data;\n",
    "- `votes.xml` - converted votes data;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "50b86498-eb40-4be6-ac98-d17d5b779a60",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import xml.sax\n",
    "import csv\n",
    "\n",
    "class DataDocumentHandler(xml.sax.ContentHandler):\n",
    "    def __init__(self, output_file_name, attributes_to_include):\n",
    "        super().__init__()\n",
    "        self.csvfile = open(output_file_name, \"w\", newline='', encoding='utf-8')\n",
    "        self.csvwriter = csv.writer(self.csvfile)\n",
    "        self.headers_written = False\n",
    "        self.rows_processed = 0\n",
    "        self.attributes_to_include = attributes_to_include\n",
    "\n",
    "        print(f\"Initialized handler and opened {output_file_name} for writing.\")\n",
    "\n",
    "    def startElement(self, name, attrs):\n",
    "        if name == 'row':\n",
    "            self.rows_processed += 1\n",
    "            row_data = {a: attrs.getValue(a) for a in self.attributes_to_include if a in attrs}\n",
    "            if not self.headers_written:\n",
    "                self.csvwriter.writerow(self.attributes_to_include)\n",
    "                self.headers_written = True\n",
    "                print(\"CSV headers written.\")\n",
    "            self.csvwriter.writerow([row_data.get(a, None) for a in self.attributes_to_include])\n",
    "\n",
    "    def endDocument(self):\n",
    "        self.csvfile.close()\n",
    "        print(f\"Finished processing and closed the file. Total rows processed: {self.rows_processed}\")\n",
    "\n",
    "    def startDocument(self):\n",
    "        print(\"Started processing XML document.\")\n",
    "\n",
    "\n",
    "def prepare_data(xml_file: str, csv_file: str, attributes_to_include: set[str]):\n",
    "    parser = xml.sax.make_parser()\n",
    "    parser.setFeature(xml.sax.handler.feature_namespaces, 0)\n",
    "\n",
    "    handler = DataDocumentHandler(csv_file, attributes_to_include)\n",
    "    parser.setContentHandler(handler)\n",
    "\n",
    "    print(f\"Starting XML parsing: {xml_file}\")\n",
    "    parser.parse(xml_file)\n",
    "    print(\"XML parsing completed successfully.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93a5f3f8f80baab7",
   "metadata": {},
   "source": [
    "#### Convert posts data dump\n",
    "Convert `Posts.xml` file that contains Stackoverflow posts (questions and answers) into CSV."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9f12dcfb-2dec-4285-93db-47bea7b1c75e",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialized handler and opened posts.csv for writing.\n",
      "Starting XML parsing: Posts.xml\n",
      "Started processing XML document.\n",
      "CSV headers written.\n",
      "Finished processing and closed the file. Total rows processed: 59749049\n",
      "XML parsing completed successfully.\n"
     ]
    }
   ],
   "source": [
    "posts_xml_file = \"Posts.xml\"\n",
    "posts_file_path = get_file_path(\"posts.csv\")\n",
    "posts_attributes_to_include = {\n",
    "    'Id', # this field is used for later analysis\n",
    "    'PostTypeId', # this field is used for later analysis\n",
    "    'ParentId', # this field is used for later analysis\n",
    "    'CreationDate', # this field is used for later analysis\n",
    "    'DeletionDate', # this field is used to filter out deleted posts\n",
    "    'Tags', # this field is used to explore tags\n",
    "    'ClosedDate' # this field is used to filter out closed posts\n",
    "}\n",
    "\n",
    "prepare_data(posts_xml_file, posts_file_path, posts_attributes_to_include)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30442c174d2209df",
   "metadata": {},
   "source": [
    "#### Convert votes data dump\n",
    "Convert `Votes.xml` file that contains Stackoverflow votes for posts into CSV."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "eb4c3809-cbcf-4e3e-998d-7ba39fb95cc2",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialized handler and opened votes.csv for writing.\n",
      "Starting XML parsing: Votes.xml\n",
      "Started processing XML document.\n",
      "CSV headers written.\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[3], line 9\u001b[0m\n\u001b[1;32m      2\u001b[0m votes_csv_file \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mvotes.csv\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m      3\u001b[0m votes_attributes_to_include \u001b[38;5;241m=\u001b[39m {\n\u001b[1;32m      4\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mPostId\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;66;03m# need for analysis\u001b[39;00m\n\u001b[1;32m      5\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mVoteTypeId\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;66;03m# need for analysis\u001b[39;00m\n\u001b[1;32m      6\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mCreationDate\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;66;03m# need for analysis\u001b[39;00m\n\u001b[1;32m      7\u001b[0m }\n\u001b[0;32m----> 9\u001b[0m \u001b[43mprepare_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvotes_xml_file\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvotes_csv_file\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvotes_attributes_to_include\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[1], line 41\u001b[0m, in \u001b[0;36mprepare_data\u001b[0;34m(xml_file, csv_file, attributes_to_include)\u001b[0m\n\u001b[1;32m     38\u001b[0m parser\u001b[38;5;241m.\u001b[39msetContentHandler(handler)\n\u001b[1;32m     40\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mStarting XML parsing: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mxml_file\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m---> 41\u001b[0m \u001b[43mparser\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mparse\u001b[49m\u001b[43m(\u001b[49m\u001b[43mxml_file\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     42\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mXML parsing completed successfully.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/xml/sax/expatreader.py:111\u001b[0m, in \u001b[0;36mExpatParser.parse\u001b[0;34m(self, source)\u001b[0m\n\u001b[1;32m    109\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mreset()\n\u001b[1;32m    110\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_cont_handler\u001b[38;5;241m.\u001b[39msetDocumentLocator(ExpatLocator(\u001b[38;5;28mself\u001b[39m))\n\u001b[0;32m--> 111\u001b[0m     \u001b[43mxmlreader\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mIncrementalParser\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mparse\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msource\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    112\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m:\n\u001b[1;32m    113\u001b[0m     \u001b[38;5;66;03m# bpo-30264: Close the source on error to not leak resources:\u001b[39;00m\n\u001b[1;32m    114\u001b[0m     \u001b[38;5;66;03m# xml.sax.parse() doesn't give access to the underlying parser\u001b[39;00m\n\u001b[1;32m    115\u001b[0m     \u001b[38;5;66;03m# to the caller\u001b[39;00m\n\u001b[1;32m    116\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_close_source()\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/xml/sax/xmlreader.py:125\u001b[0m, in \u001b[0;36mIncrementalParser.parse\u001b[0;34m(self, source)\u001b[0m\n\u001b[1;32m    123\u001b[0m buffer \u001b[38;5;241m=\u001b[39m file\u001b[38;5;241m.\u001b[39mread(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_bufsize)\n\u001b[1;32m    124\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m buffer:\n\u001b[0;32m--> 125\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfeed\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbuffer\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    126\u001b[0m     buffer \u001b[38;5;241m=\u001b[39m file\u001b[38;5;241m.\u001b[39mread(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_bufsize)\n\u001b[1;32m    127\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mclose()\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/xml/sax/expatreader.py:217\u001b[0m, in \u001b[0;36mExpatParser.feed\u001b[0;34m(self, data, isFinal)\u001b[0m\n\u001b[1;32m    210\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_cont_handler\u001b[38;5;241m.\u001b[39mstartDocument()\n\u001b[1;32m    212\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    213\u001b[0m     \u001b[38;5;66;03m# The isFinal parameter is internal to the expat reader.\u001b[39;00m\n\u001b[1;32m    214\u001b[0m     \u001b[38;5;66;03m# If it is set to true, expat will check validity of the entire\u001b[39;00m\n\u001b[1;32m    215\u001b[0m     \u001b[38;5;66;03m# document. When feeding chunks, they are not normally final -\u001b[39;00m\n\u001b[1;32m    216\u001b[0m     \u001b[38;5;66;03m# except when invoked from close.\u001b[39;00m\n\u001b[0;32m--> 217\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_parser\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mParse\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43misFinal\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    218\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m expat\u001b[38;5;241m.\u001b[39merror \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    219\u001b[0m     exc \u001b[38;5;241m=\u001b[39m SAXParseException(expat\u001b[38;5;241m.\u001b[39mErrorString(e\u001b[38;5;241m.\u001b[39mcode), e, \u001b[38;5;28mself\u001b[39m)\n",
      "File \u001b[0;32m/home/conda/feedstock_root/build_artifacts/python-split_1703344859861/work/Modules/pyexpat.c:468\u001b[0m, in \u001b[0;36mEndElement\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/xml/sax/expatreader.py:335\u001b[0m, in \u001b[0;36mExpatParser.end_element\u001b[0;34m(self, name)\u001b[0m\n\u001b[1;32m    332\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mstart_element\u001b[39m(\u001b[38;5;28mself\u001b[39m, name, attrs):\n\u001b[1;32m    333\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_cont_handler\u001b[38;5;241m.\u001b[39mstartElement(name, AttributesImpl(attrs))\n\u001b[0;32m--> 335\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mend_element\u001b[39m(\u001b[38;5;28mself\u001b[39m, name):\n\u001b[1;32m    336\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_cont_handler\u001b[38;5;241m.\u001b[39mendElement(name)\n\u001b[1;32m    338\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mstart_element_ns\u001b[39m(\u001b[38;5;28mself\u001b[39m, name, attrs):\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "votes_xml_file = \"Votes.xml\"\n",
    "votes_csv_path = get_file_path(\"votes.csv\")\n",
    "votes_attributes_to_include = {\n",
    "    'PostId', # need for analysis\n",
    "    'VoteTypeId', # need for analysis\n",
    "    'CreationDate' # need for analysis\n",
    "}\n",
    "\n",
    "prepare_data(votes_xml_file, votes_csv_path, votes_attributes_to_include)"
   ]
  }
 ],
 "metadata": {
  "environment": {
   "kernel": "conda-root-py",
   "name": "workbench-notebooks.m118",
   "type": "gcloud",
   "uri": "us-docker.pkg.dev/deeplearning-platform-release/gcr.io/workbench-notebooks:m118"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
