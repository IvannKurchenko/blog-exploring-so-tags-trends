{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2a29fb89-0199-461e-a53d-d1de548bac6b",
   "metadata": {},
   "source": [
    "## Notebook to convert data into from XML into CSV\n",
    "\n",
    "### Description\n",
    "The main objective of this notebook is to convert Stackoverflow data dump `*.xml` documents into `*.csv` format.\n",
    "The former one is then used for all transformations and calculations, because it is easier to operate with using Pandas.\n",
    "\n",
    "In particularly it converts each row from XML document into CSV and specific attributes into columns. Some attributes are filtered out because they are not relevant for aggregations to make.\n",
    "\n",
    "\n",
    "For instance, `Posts.xml` have the following structure:\n",
    "```xml\n",
    "<?xml version=\"1.0\" encoding=\"utf-8\"?>\n",
    "<posts>\n",
    "  <row Id=\"4\" PostTypeId=\"1\" AcceptedAnswerId=\"7\" CreationDate=\"2008-07-31T21:42:52.667\" Score=\"804\" ViewCount=\"76276\" Body=\"&lt;p&gt;I want to assign the decimal variable &amp;quot;trans&amp;quot; to the double variable &amp;quot;this.Opacity&amp;quot;.&lt;/p&gt;&#xA;&lt;pre class=&quot;lang-cs prettyprint-override&quot;&gt;&lt;code&gt;decimal trans = trackBar1.Value / 5000;&#xA;this.Opacity = trans;&#xA;&lt;/code&gt;&lt;/pre&gt;&#xA;&lt;p&gt;When I build the app it gives the following error:&lt;/p&gt;&#xA;&lt;blockquote&gt;&#xA;&lt;p&gt;Cannot implicitly convert type decimal to double&lt;/p&gt;&#xA;&lt;/blockquote&gt;&#xA;\" OwnerUserId=\"8\" LastEditorUserId=\"16124033\" LastEditorDisplayName=\"Rich B\" LastEditDate=\"2022-09-08T05:07:26.033\" LastActivityDate=\"2022-09-08T05:07:26.033\" Title=\"How to convert Decimal to Double in C#?\" Tags=\"&lt;c#&gt;&lt;floating-point&gt;&lt;type-conversion&gt;&lt;double&gt;&lt;decimal&gt;\" AnswerCount=\"13\" CommentCount=\"4\" FavoriteCount=\"0\" CommunityOwnedDate=\"2012-10-31T16:42:47.213\" ContentLicense=\"CC BY-SA 4.0\" />\n",
    "  <!--other rows-->\n",
    "</posts>\n",
    "```\n",
    "That will be converted into:\n",
    "```csv\n",
    "Tags,ParentId,CreationDate,Id,DeletionDate,PostTypeId,ClosedDate,Score\n",
    "<c#><floating-point><type-conversion><double><decimal>,,2008-07-31T21:42:52.667,4,,1,,804\n",
    "```\n",
    "\n",
    "### Input \n",
    "This notebook takes as an input two files from raw Stackoverflow data dump:\n",
    "- `Posts.xml` - data with raw posts data;\n",
    "- `Votes.xml` - data with raw votes data;\n",
    "\n",
    "### Output\n",
    "- `posts.csv` - converted posts data;\n",
    "- `posts.csv` - converted votes data;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "50b86498-eb40-4be6-ac98-d17d5b779a60",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import xml.sax\n",
    "import csv\n",
    "from config import get_file_path\n",
    "\n",
    "class DataDocumentHandler(xml.sax.ContentHandler):\n",
    "    def __init__(self, output_file_name, attributes_to_include):\n",
    "        super().__init__()\n",
    "        self.csvfile = open(output_file_name, \"w\", newline='', encoding='utf-8')\n",
    "        self.csvwriter = csv.writer(self.csvfile)\n",
    "        self.headers_written = False\n",
    "        self.rows_processed = 0\n",
    "        self.attributes_to_include = attributes_to_include\n",
    "\n",
    "        print(f\"Initialized handler and opened {output_file_name} for writing.\")\n",
    "\n",
    "    def startElement(self, name, attrs):\n",
    "        if name == 'row':\n",
    "            self.rows_processed += 1\n",
    "            row_data = {a: attrs.getValue(a) for a in self.attributes_to_include if a in attrs}\n",
    "            if not self.headers_written:\n",
    "                self.csvwriter.writerow(self.attributes_to_include)\n",
    "                self.headers_written = True\n",
    "                print(\"CSV headers written.\")\n",
    "            self.csvwriter.writerow([row_data.get(a, None) for a in self.attributes_to_include])\n",
    "\n",
    "    def endDocument(self):\n",
    "        self.csvfile.close()\n",
    "        print(f\"Finished processing and closed the file. Total rows processed: {self.rows_processed}\")\n",
    "\n",
    "    def startDocument(self):\n",
    "        print(\"Started processing XML document.\")\n",
    "\n",
    "\n",
    "def prepare_data(xml_file: str, csv_file: str, attributes_to_include: set[str]):\n",
    "    parser = xml.sax.make_parser()\n",
    "    parser.setFeature(xml.sax.handler.feature_namespaces, 0)\n",
    "\n",
    "    handler = DataDocumentHandler(csv_file, attributes_to_include)\n",
    "    parser.setContentHandler(handler)\n",
    "\n",
    "    print(f\"Starting XML parsing: {xml_file}\")\n",
    "    parser.parse(xml_file)\n",
    "    print(\"XML parsing completed successfully.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93a5f3f8f80baab7",
   "metadata": {},
   "source": [
    "#### Convert posts data dump\n",
    "Convert `Posts.xml` file that contains Stackoverflow posts (questions and answers) into CSV."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9f12dcfb-2dec-4285-93db-47bea7b1c75e",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialized handler and opened data/analysis/posts.csv for writing.\n",
      "Starting XML parsing: Posts.xml\n",
      "Started processing XML document.\n",
      "CSV headers written.\n",
      "Finished processing and closed the file. Total rows processed: 59749049\n",
      "XML parsing completed successfully.\n"
     ]
    }
   ],
   "source": [
    "posts_xml_file = \"Posts.xml\"\n",
    "posts_file_path = get_file_path(\"posts.csv\")\n",
    "posts_attributes_to_include = {\n",
    "    'Id', # this field is used for later analysis\n",
    "    'PostTypeId', # this field is used for later analysis\n",
    "    'ParentId', # this field is used for later analysis\n",
    "    'CreationDate', # this field is used for later analysis\n",
    "    'DeletionDate', # this field is used to filter out deleted posts\n",
    "    'Tags', # this field is used to explore tags\n",
    "    'Score', # this field is used for later analysis\n",
    "    'ViewCount', # this field is used for later analysis\n",
    "    'CommentCount', # this field is used for later analysis\n",
    "    'FavoriteCount', # this field is used for later analysis\n",
    "    'ClosedDate' # this field is used to filter out closed posts\n",
    "}\n",
    "\n",
    "prepare_data(posts_xml_file, posts_file_path, posts_attributes_to_include)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74789b31-af1d-45f8-9442-29dc39bf75a8",
   "metadata": {},
   "source": [
    "#### Convert votes data dump\n",
    "Convert `Votes.xml` file that contains Stackoverflow votes for posts into CSV."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2dea15da-ccad-444f-850b-f5a417832039",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialized handler and opened data/analysis/votes.csv for writing.\n",
      "Starting XML parsing: Votes.xml\n",
      "Started processing XML document.\n",
      "CSV headers written.\n",
      "Finished processing and closed the file. Total rows processed: 238041583\n",
      "XML parsing completed successfully.\n"
     ]
    }
   ],
   "source": [
    "votes_xml_file = \"Votes.xml\"\n",
    "votes_csv_path = get_file_path(\"votes.csv\")\n",
    "votes_attributes_to_include = {\n",
    "    'PostId', # need for analysis\n",
    "    'VoteTypeId', # need for analysis\n",
    "    'CreationDate' # need for analysis\n",
    "}\n",
    "\n",
    "prepare_data(votes_xml_file, votes_csv_path, votes_attributes_to_include)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b6d9c50-35e5-40c5-a6e7-522f5626736e",
   "metadata": {},
   "source": [
    "#### Convert comments data dump\n",
    "Convert `Comments.xml` file that contains Stackoverflow votes for posts into CSV."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "08cb35d4-c3c2-4cd8-9bcf-65a96f363bde",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialized handler and opened data/analysis/comments.csv for writing.\n",
      "Starting XML parsing: Comments.xml\n",
      "Started processing XML document.\n",
      "CSV headers written.\n",
      "Finished processing and closed the file. Total rows processed: 90320000\n",
      "XML parsing completed successfully.\n"
     ]
    }
   ],
   "source": [
    "comments_xml_file = \"Comments.xml\"\n",
    "comments_csv_path = get_file_path(\"comments.csv\")\n",
    "comments_attributes_to_include = {\n",
    "    'PostId', # need for analysis\n",
    "    'CreationDate' # need for analysis\n",
    "}\n",
    "\n",
    "prepare_data(comments_xml_file, comments_csv_path, comments_attributes_to_include)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30c96d2a-5f9e-40fc-9820-129412a3ce80",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "environment": {
   "kernel": "conda-root-py",
   "name": "workbench-notebooks.m118",
   "type": "gcloud",
   "uri": "us-docker.pkg.dev/deeplearning-platform-release/gcr.io/workbench-notebooks:m118"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
